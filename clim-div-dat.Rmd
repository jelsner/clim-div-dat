---
title: "Climate Division Data"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r}
library(tidyverse)
```

## Climate data

https://data.nodc.noaa.gov/cgi-bin/iso?id=gov.noaa.ncdc:C00005#

From the county-readme.txt file:

climdiv-pcpncy-vx.y.z-YYYYMMDD
climdiv-tmaxcy-vx.y.z-YYYYMMDD
climdiv-tmincy-vx.y.z-YYYYMMDD
climdiv-tmpccy-vx.y.z-YYYYMMDD

The variables in this file are sequential climatic county  monthly maximum, minimum and average temperature (deg. F. to 10ths) and precipitation (inches to 100ths). 
Period of record is 1895 through latest month available, updated monthly. Values from the most recent two calendar years will be updated on a monthly 
basis.  Period of record updates will occur when the underlying data set undergoes a version change.

County values in nClimDiv were derived from area-weighted averages of grid-point estimates interpolated from station data.  A nominal grid resolution of 5 km 
was used to ensure that all divisions had sufficient spatial sampling (only four small divisions had less than 100 points) and because the impact of 
elevation on precipitation is minimal below 5 km.  Station data were gridded via climatologically aided interpolation to minimize biases from topographic 
and network variability.

The Global Historical Climatology Network (GHCN)  Daily dataset is the source of station data for nClimDiv.  GHCN-Daily contains several major observing 
networks in North America, five of which are used here.  The primary network is the National Weather Service (NWS) Cooperative Observing (COOP) program, 
which consists of stations operated by volunteers as well as by agencies such as the Federal Aviation Administration.  To improve coverage in western states 
and along international borders, nClimDiv also includes the National Interagency Fire Center (NIFC) Remote Automatic Weather Station (RAWS) network, 
the USDA Snow Telemetry (SNOTEL) network, the Environment Canada (EC) network (south of 52N), and part of Mexicos Servicio Meteorologico Nacional 
(SMN) network (north of 24N).  Note that nClimDiv does not incorporate precipitation data from RAWS because that networks tipping-bucket gauges are 
unheated, leading to suspect cold-weather data.

All GHCN-Daily stations are routinely processed through a suite of logical, serial, and spatial quality assurance reviews to identify erroneous 
observations.  For nClimDiv, all such data were set to missing before computing monthly values, which in turn were subjected to additional serial 
and spatial checks to eliminate residual outliers. Stations having at least 10 years of valid monthly data since 1950 were used in nClimDiv.

For temperature, bias adjustments were computed to account for historical changes in observation time, station location, temperature instrumentation, 
and siting conditions.  Changes in observation time are only problematic for the COOP network whereas changes in station location and instrumentation occur 
in almost all surface networks.   As in the U.S. Historical Climatology Network version 2.5, the method of Karl et al. (1986) was applied to remove the 
observation time bias from the COOP network, and the pairwise method of Menne and Williams (2009) was used to address changes in station location and 
instrumentation in all networks.  Because the pairwise method also largely accounts for local, unrepresentative trends that arise from changes in siting 
conditions, nClimDiv contains no separate adjustment in that regard. For additional information on how nClimDiv is constructed, please see:
http://journals.ametsoc.org/doi/abs/10.1175/JAMC-D-13-0248.1

STATE CODE TABLE: Range of values of 01-48.

01 Alabama 01                28 New Jersey 34
02 Arizona 04                29 New Mexico 35
03 Arkansas 05               30 New York 36
04 California 06             31 North Carolina 37
05 Colorado 08               32 North Dakota 38
06 Connecticut 09            33 Ohio 39
07 Delaware 10               34 Oklahoma 40
08 Florida 12                35 Oregon 41
09 Georgia 13                36 Pennsylvania 42
10 Idaho 16                  37 Rhode Island 44
11 Illinois 17               38 South Carolina 45
12 Indiana 18                39 South Dakota 46
13 Iowa 19                   40 Tennessee 47
14 Kansas 20                 41 Texas 48
15 Kentucky 21               42 Utah 49
16 Louisiana 22              43 Vermont 50
17 Maine 23                  44 Virginia 51
18 Maryland 24               45 Washington 53
19 Massachusetts 25          46 West Virginia 54
20 Michigan 26               47 Wisconsin 55
21 Minnesota 27              48 Wyoming 56
22 Mississippi 28
23 Missouri 29  
24 Montana 30  
25 Nebraska 31
26 Nevada 32 
27 New Hampshire 33

```{r}
stfips <- c("01", "04", "05", "06", "08", "09", "10", "12", "13", "16", "17", "18", "19", "20", "21", "22", "23", "24",
            "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37", "38", "39", "40", "41", "42",
            "44", "45", "46", "47", "48", "49", "50", "51", "53", "54", "55", "56")

url <- "ftp://ftp.ncdc.noaa.gov/pub/data/cirs/climdiv/climdiv-tmaxcy-v1.0.0-20190805"
df <- read.table(file = url,
                 colClasses = c("character", rep("numeric", times = 12)),
                 col.names = c("ID_Year", month.name)) %>%
  transform(STID = as.integer(substr(ID_Year, 1, 2)),
            CTYFIPS = substr(ID_Year, 3, 5),
            DataType = substr(ID_Year, 6, 7),
            Year = as.numeric(substr(ID_Year, 8, 11))) %>%
  mutate(STFIPS = stfips[STID],
         FIPS = paste0(STFIPS, CTYFIPS)) %>%
  select(FIPS, STFIPS, Year, month.name)
```

Leon County Florida is STID = 08, CTYFIPS = 073 (see `county-readme.txt`).
```{r}
Climate <- df %>%
  filter(FIPS == "12073") %>%
  filter(Year < 2019)

coef(lm(April ~ Year, data = Climate))

X <- Climate %>%
  filter(Year %in% seq(1900, 2010, by = 10)) 
coef(lm(April ~ Year, data = X))
```

Plot a single month.
```{r}
ggplot(Climate, aes(x = Year, y = February)) +
  geom_point() +
  geom_smooth(method = lm)
```

Make a long data frame.
```{r}
ClimateL <- Climate %>%
  select(Year, January, February, March, April, May, June, July, 
         August, September, October, November, December) %>%
  gather(key = Year,
         value = "Variable",
         factor_key = TRUE) %>%
  rename(Month = Year) %>%
  mutate(Year = rep(1900:2018, times = 12))
head(ClimateL)
```

The `gather()` function takes all the values as measured except those named in `key =` argument. All variables are measured (e.g., precipitation in units of hundredths of inches) except `Year`. `Year` is a vector identifying the month. The long data frame lists the key variable names as the first column taking the column names as character strings starting with `January`. To preserve the order of the columns (e.g., January comes before February, etc) we specify the `factor_key = TRUE`. We use `rename()` to give the key variable the correct name.

```{r}
ggplot(ClimateL, aes(x = Year, y = Variable)) +
  geom_point() +
  geom_smooth(method = lm) +
  facet_wrap(~ Month)
```

Without the points and on a single graph. Slope graph.
```{r}
ggplot(ClimateL, aes(x = Year, y = Variable, color = Month)) +
  geom_smooth(method = lm, se = FALSE)
```

Improve the slope graph. Use the `map()` function in the **purrr** package (part of the **tidyverse**).
```{r}
library(reshape2)

Predictions <- ClimateL %>%
  split(.$Month) %>%  # base R
  map(~ lm(Variable ~ Year, data = .)) %>%
  map(predict, newdata = data.frame(Year = c(1940, 2018))) %>%
  as.data.frame() %>%
  mutate(Year = c("1940", "2018")) %>%
  mutate_if(is.numeric, ~round(., 1)) %>%
  melt(id.vars = "Year")
```

Get code from Chuck Powell: https://ibecav.github.io/CGPfunctions/reference/newggslopegraph.html
```{r}
library(CGPfunctions)
```

Use his code directly.
```{r}
newggslopegraph(Predictions, Year, value, variable,
#                Title = "Monthly Average Temperatures (Â°F)",
                Title = "Monthly Average Precipitation (in)",
                SubTitle = "Leon County, FL",
                LineColor = "gray50",
                Caption = "Data: NOAA, nCLIMDIV",
                LineThickness = .5,
                YTextSize = 3,
                DataLabelPadding = .05)
```

From scratch.
```{r}
MySpecial <- list(  
  # move the x axis labels up top
  scale_x_discrete(position = "top"),
  theme_bw(),
  # Format tweaks
  # Remove the legend
  theme(legend.position = "none"),
  # Remove the panel border
  theme(panel.border     = element_blank()),
  # Remove just about everything from the y axis
  theme(axis.title.y     = element_blank()),
  theme(axis.text.y      = element_blank()),
  theme(panel.grid.major.y = element_blank()),
  theme(panel.grid.minor.y = element_blank()),
  # Remove a few things from the x axis and increase font size
  theme(axis.title.x     = element_blank()),
  theme(panel.grid.major.x = element_blank()),
  theme(axis.text.x.top      = element_text(size=12)),
  # Remove x & y tick marks
  theme(axis.ticks       = element_blank()),
  # Format title & subtitle
  theme(plot.title       = element_text(size=14, face = "bold", hjust = 0.5)),
  theme(plot.subtitle    = element_text(hjust = 0.5))
)

library(ggrepel)

ggplot(data = Predictions, aes(x = Year, y = value, group = variable)) +
  geom_line(color = "gray", size = .5) +
  geom_text_repel(data = Predictions %>% filter(Year == "1940"), 
                  aes(label = variable) , 
                  hjust = "left", 
                  fontface = "bold", 
                  size = 3, 
                  nudge_x = -.45, 
                  direction = "y") +
  geom_text_repel(data = Predictions %>% filter(Year == "2018"), 
                  aes(label = variable) , 
                  hjust = "right", 
                  fontface = "bold", 
                  size = 3, 
                  nudge_x = .5, 
                  direction = "y") +
  geom_label(aes(label = value), 
             size = 2.5, 
             label.padding = unit(0.05, "lines"), 
             label.size = 0.0) +
  MySpecial +
  labs(
    title = "Average Daily Low Temperature (Â°F)",
#    title = "Monthly Average Precipitation (in)",
    subtitle = "Leon County, FL",
    caption = "Data: NOAA, nCLIMDIV"
  )
```

## Population data

```{r}
library(USAboundaries)
library(sf)

KS_counties_1895 <- us_counties("1895-01-01", states = "Kansas")
plot(st_geometry(KS_counties_1895))
title("Kansas county boundaries on January 1, 1895")

KS_cities_1895 <- us_cities(map_date = 1895, states = "Kansas")
KS_cities_1995 <- us_cities(map_date = 1995, states = "Kansas")

plot(st_geometry(KS_cities_1995), col = "red", add = TRUE)
plot(st_geometry(KS_cities_1895), add = TRUE)
```

EPSG:102004 USA_Contiguous_Lambert_Conformal_Conic
+proj=lcc +lat_1=33 +lat_2=45 +lat_0=39 +lon_0=-96 +x_0=0 +y_0=0 +datum=NAD83 +units=m +no_defs

Get 2010 county boundaries.
```{r}
Counties <- us_counties(map_date = "2000-12-31", states = "Florida") %>%
  st_transform(crs = 102004)
n_counties <- nrow(Counties)
```

Create a single sf data frame with year, population, and point geometry containing the county wide total population in cities. Loop over all decennial years getting cities.
```{r}
CITY_Pop <- NULL

for(yr in seq(1890, 2010, by = 10)){
cities <- us_cities(map_date = yr, states = "Florida") %>%
  st_transform(crs = 102004) %>%
  dplyr::select(population) %>%
  aggregate(by = Counties, FUN = "sum") %>%
  mutate(CensusYear = yr, Name = Counties$name, FIPS = Counties$fips, Area = as.numeric(st_area(geometry)), popD = round(log(population/Area))) %>%
  uncount(10) %>% # duplicates data frame 10 times
  mutate(Year = rep(seq(yr, yr + 9), times = n_counties)) %>%
  dplyr::select(Name, FIPS, Year, CensusYear, population, Area, popD, geometry)

CITY_Pop <- rbind(CITY_Pop, cities)
}
CITY_Pop$population[is.na(CITY_Pop$population)] <- 0
```

Plot time series.
```{r}
library(ggplot2)
CITY_Pop %>%
  dplyr::filter(Name == "LEON") %>%
  ggplot(aes(x = Year, y = population)) +
  geom_line()

CITY_Pop %>%
  ggplot(aes(x = Year, y = population)) +
  geom_line() +
  facet_wrap(~ Name)
```

## Combine population data with climate data

Get the temperature data
```{r}
stfips <- c("01", "04", "05", "06", "08", "09", "10", "12", "13", "16", "17", "18", "19", "20", "21", "22", "23", "24",
            "25", "26", "27", "28", "29", "30", "31", "32", "33", "34", "35", "36", "37", "38", "39", "40", "41", "42",
            "44", "45", "46", "47", "48", "49", "50", "51", "53", "54", "55", "56")

url <- "ftp://ftp.ncdc.noaa.gov/pub/data/cirs/climdiv/climdiv-tmpccy-v1.0.0-20190805"
df <- read.table(file = url,
                 colClasses = c("character", rep("numeric", times = 12)),
                 col.names = c("ID_Year", month.name)) %>%
  transform(STID = as.integer(substr(ID_Year, 1, 2)),
            CTYFIPS = substr(ID_Year, 3, 5),
            DataType = substr(ID_Year, 6, 7),
            Year = as.numeric(substr(ID_Year, 8, 11))) %>%
  mutate(STFIPS = stfips[STID],
         FIPS = paste0(STFIPS, CTYFIPS)) %>%
  select(FIPS, STFIPS, Year, month.name)
```

Leon County only. Remove years before 2019.  Orlando (Orange County) 12095, Miami (Miami-Dade) 12086, Leon 12073
```{r}
Climate <- df %>%
  filter(FIPS == "12073") %>%
  filter(Year < 2019)
```

```{r}
Test <- Climate %>%
  left_join(CITY_Pop) %>%
  filter(!is.na(Name))
```

Make a long data frame.
```{r}
TestL <- Test %>%
  dplyr::select(Year, January, February, March, April, May, June, July, 
         August, September, October, November, December) %>%
  gather(key = Year,
         value = "Variable",
         factor_key = TRUE) %>%
  rename(Month = Year, Temperature = Variable) %>%
  mutate(Year = rep(Test$Year, times = 12),
         population = rep(Test$population, times = 12))
head(TestL)
```

## Model

Use the population density (rounded) as a random effect.
```{r}
library(brms)

TestL <- TestL %>%
  mutate(YearCentered = Year - round(median(Year)),
         TemperatureCentered = Temperature - median(Temperature),
         PopulationCentered = population - median(population))


family <- gaussian()
formula <- TemperatureCentered ~ YearCentered + (1 | Month) + (1 | population)

formula <- TemperatureCentered ~ YearCentered  + PopulationCentered + (1 | Month)

#formula <- TemperatureCentered ~ YearCentered + (1 | Month) 
#formula <- TemperatureCentered ~ YearCentered + (1 | popD)
#formula <- TemperatureCentered ~ YearCentered

get_prior(formula, data = TestL, family = family)

fit1 <- brm(formula = formula,
            data = TestL,
            family = family,
            prior = c(set_prior("normal(0, 5)", class = "b"),
                     set_prior("student_t(3, 0, 17)", class = "Intercept"),
                     set_prior("student_t(3, 0, 17)", class = "sd"),
                     set_prior("student_t(3, 0, 17)", class = "sigma")),
#                     set_prior("lkj(1)", class = "cor")),
           control = list(adapt_delta = .9, max_treedepth = 20),
           seed = 1878121)

fixef(fit1)
ranef(fit1)
```
